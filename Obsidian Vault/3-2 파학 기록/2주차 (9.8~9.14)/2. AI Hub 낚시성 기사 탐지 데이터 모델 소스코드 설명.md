## 낚시성 기사 탐지 데이터

- 구축환경정보
- 도커이미지
- 모델소스코드
- 모델정보 및 라이센스 가이드
    - 1세부_HAND모델설명, README, 코드설명
    - 2세부_BERT모델설명, README, 코드설명
- 학습모델파일

---

## 구축환경정보

- `requirements.txt` 파일 존재
```
- AI 모델을 실행하기 위해 필요한 라이브러리와 버전을 정의한 환경 설정 파일
- `pip install -r requirements.txt` 명령어를 실행하면, 같은 환경을 손쉽게 재현 가능
```

- `requirements.txt` 파일에 명시된 주요 라이브러리
	- 딥러닝 프레임워크
	    - `torch`, `torchvision`, `torchtext`: PyTorch 기반 모델 학습/추론
	    - `tensorflow`, `tensorflow-text`: TensorFlow 관련 기능 (일부 코드 호환성)
	    - `onnx`, `onnxruntime`: 학습된 모델을 ONNX 포맷으로 변환·실행
	- 자연어처리(NLP)
	    - `transformers`, `pytorch-transformers`: Hugging Face 기반 BERT/KoBERT 등 사전학습 모델 활용
	    - `sentencepiece`, `tokenizers`: 토크나이저 라이브러리
	    - `kobert` (SKTBrain/KoBERT GitHub): 한국어 특화 BERT 모델
	    - `konlpy`, `kss`: 한국어 형태소 분석기, 문장 분리 도구
	- 데이터 처리/분석
	    - `pandas`, `numpy`, `scikit-learn`, `scipy`: 데이터 전처리와 분석용
	    - `matplotlib`, `seaborn`: 시각화
	- 크롤링 및 전처리
	    - `beautifulsoup4`, `lxml`, `html2text`: HTML 파싱
	    - `gdown`: Google Drive 데이터 다운로드
	- 모델 학습 지원 도구
	    - `captum`: 모델 해석(XAI)
	    - `optuna`는 없지만, `wandb`, `tensorboard`, `tensorboardX` 등 로그 및 학습 모니터링 도구 포함
	    - `apex`, `nvidia-dali`, `tensorrt`: NVIDIA GPU 최적화

---

## 도커이미지

- Dockerfile, fake_news.tar 폴더, 메뉴얼.txt 존재
```
- Dockerfile
	- 도커 이미지를 빌드하기 위한 설정 파일
- fake_news.tar
	- 미리 빌드된 도커 이미지가 압축된 파일
	- Dockerfile을 실행하지 않고도 곧바로 모델 실행 환경 준비 가능
- 메뉴얼.txt
	- 도커 이미지 설치 및 실행 방법에 대한 가이드 문서
```

- 도커 이미지 세 가지 설치 방식
	1. `docker pull dsbalab/fake_news` (도커허브에서 바로 받기)
	2. `docker build -t $image_name .` (Dockerfile을 이용해 직접 빌드하기)
	3. `docker load -i fake_news.tar` (tar 파일에서 불러오기)

- 낚시성 뉴스 탐지 모델 실행 방법
	- Part1 (제목–본문 불일치 기사) → HAND 모델
	- Part2 (본문 내 도메인 일관성 부족 기사) → BTS(BERT for Topic Segmentation) 모델
	- 각각 `main.py` 실행 시 yaml 설정 파일(`HAND-train.yaml`, `BTS-train.yaml`)을 지정해서 학습/평가를 수행

---

## 모델소스코드

- GitHub 레포지토리의 모델소스코드
	- https://github.com/TooTouch/Fake-News-Detection-Dataset.git



---

## 모델정보 및 라이센스 가이드

- 1세부의 HAND모델설명, README, 코드설명 파일 존재
- 2세부의 BERT모델설명, README, 코드설명 파일 존재

### 1세부 내용 정리

#### 1. 과업(Task1) 개요
- **주제**: 뉴스 기사 **제목과 본문 간 일치 여부**를 탐지하여 가짜 뉴스를 분류하는 과업.
- **모델**: HAND(Hierarchical Attention Networks for Document Classification) 모델을 중심으로 함.
#### 2. 데이터셋
- **규모**:
    - Train: 291,466건
    - Validation: 36,434건
    - Test: 36,433건
- **Target 클래스**:
    - Clickbait_Direct (직접 작성된 낚시 기사)
    - Clickbait_Auto (자동 생성 낚시 기사)
    - NonClickbait_Auto (자동 생성 비낚시 기사)
- **카테고리 분포**: EC, ET, GB, IS, LC, PO, SO 등 7개.
#### 3. 모델 (HAND)
- **구조**:
    - 단어 임베딩 입력 → GRU 인코딩 → Word Attention → 단어 표현 생성
    - 문장 단위 벡터 → GRU 인코딩 → Sentence Attention → 문서 표현 생성
- **입출력**:
    - Input: (Batch, Sentence Length=16, Word Length=64)
    - Output: (Batch, 2) (이진 분류)
- **학습 설정** (`HAND-train.yaml` 기준):
    - Batch size = 256
    - Optimizer: AdamW (lr=0.003, weight_decay=0.0005)
    - Training steps: 30,000
    - WandB 로깅 지원
#### 4. 코드 구조
- **configs/HAND**: yaml 설정 파일 (save_dataloader, train, test)
- **dataset/**:
    - `FakeDataset`: 기본 데이터셋 로더
    - `HANDDataset`: HAND 입력 형식(문장×단어) 토큰화/패딩
    - `FNDTokenizer`: Mecab 기반 토크나이저
    - `factory.py`: 토크나이저/데이터셋/로더 생성 함수
- **models/**:
    - `hand.py`: HierAttNet, WordAttnNet, SentAttnNet 정의
    - `factory.py`: 모델 생성
    - `registry.py`: 모델 레지스트리
- **실행 스크립트**:
    - `save_dataloader.py`: 데이터셋 캐시 생성
    - `main.py`: 학습/테스트 실행
    - `train.py`: 학습 루프
    - `log.py`, `utils.py`: 로깅 및 유틸
#### 5. 학습/실행 방법
1. 데이터셋 캐시 저장
```bash
python save_dataloader.py --yaml_config ./configs/HAND/HAND_save_dataloader.yaml
```
2. 모델 학습/평가
```bash
python main.py --yaml_config ./configs/HAND/HAND-train.yaml
python main.py --yaml_config ./configs/HAND/HAND-test.yaml
```
3. Fine-tuning 시: `checkpoint_path`를 지정하여 기존 모델 가중치 불러오기.
#### 6. 성능 결과
- **HAND 성능 지표**:
    - AUROC = 0.945
    - F1 = 0.867
    - Recall = 0.842
    - Precision = 0.893
    - Accuracy = 0.870
- **오분류 사례 비율**:
    - NonClickbait_Auto: 10.13%
    - Clickbait_Auto: 16.31%
    - Clickbait_Direct: 14.30%

### 2세부 내용 정리
#### 1. 과업(Task2) 개요
- **주제**: 뉴스 기사 **본문 내 문장 간 일관성**을 탐지하여 가짜 뉴스를 분류하는 과업.
- **모델**: **BTS (BERT for Topic Segmentation)** – 한국어 BERT를 활용해 연속된 두 문장의 연관성을 파악하고 일관성 여부에 따라 분류.
#### 2. 데이터셋
- **규모**:
    - Train: 295,275건
    - Validation: 36,910건
    - Test: 36,909건
- **Target 클래스**:
    - Clickbait_Direct (직접 작성된 낚시 기사)
    - Clickbait_Auto (자동 생성 낚시 기사)
    - NonClickbait_Auto (자동 생성 비낚시 기사)
- **카테고리 분포**: EC, ET, GB, IS, LC, PO, SO 등 7개.
#### 3. 모델 (BTS)
- **구조**:
    - 입력: 연속된 두 문장을 `[SEP]` 토큰으로 연결 → BERT 입력
    - BERT 인코딩 결과로 각 문장의 관계를 분류
- **입출력**:
    - Input: (Batch, Max input length=512)
        - `src`: 토큰 인덱스
        - `segs`: segment 구분 id
        - `mask_src`: padding 마스크
    - Output: (Batch, 2) (이진 분류)
- **학습 설정** (`BTS-train.yaml` 기준):
    - Batch size = 8
    - Optimizer: AdamW (lr=1e-5, weight_decay=0.0005)
    - Training steps: 15,000
    - Scheduler: warmup ratio=0.1, 사용=True
    - WandB 로깅 지원
- **평가지표**: Accuracy, F1-score
#### 4. 코드 구조
- **configs/BTS**: 학습/평가 yaml 설정 파일
- **dataset/**:
    - `FakeDataset`: 기본 데이터셋 로더, window_size 단위로 문장 묶음 구성
    - `BTSDataset`: BTS 전용 데이터셋 (토큰화, 세그먼트 id, 마스크 생성)
    - `factory.py`: 데이터셋/로더 생성
- **models/**:
    - `bts.py`: BTS 모델 구현 (BERT 기반 forward)
    - `factory.py`: 모델 생성
    - `registry.py`: 모델 레지스트리
- **실행 스크립트**:
    - `main.py`: 학습/테스트 실행
    - `train.py`: 학습 루프
    - `run.sh`: 실행 쉘 스크립트
    - `log.py`, `utils.py`: 로깅 및 유틸
- **saved_model/BTS**: 학습된 모델과 결과(best/last 가중치, 점수 json/csv) 저장
#### 5. 학습/실행 방법
1. 모델 학습/평가
```bash
python main.py --yaml_config ./configs/BTS/BTS-train.yaml
python main.py --yaml_config ./configs/BTS/BTS-test.yaml
```
2. Fine-tuning 시: `checkpoint_path`를 지정해 기존 모델 가중치 불러오기.
#### 6. 성능 결과
- **BTS 성능 지표**:
    - AUROC = 0.989
    - F1 = 0.908
    - Recall = 0.899
    - Precision = 0.917
    - Accuracy = 0.986
    - ACC_PER_ARTICLE = 0.839
- **오분류 사례 비율**:
    - NonClickbait_Auto: 7.25%
    - Clickbait_Auto: 27.58%
    - Clickbait_Direct: 16.87%

