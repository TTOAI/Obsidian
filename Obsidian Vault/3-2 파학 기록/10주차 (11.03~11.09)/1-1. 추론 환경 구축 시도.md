
### Conda 기본 명령어

- 현재 conda 환경 목록 확인
```
conda env list
```

- 환경 삭제
```
conda env remove -n {env_name}
```

- 불필요한 캐시 정리
```
conda clean -a -y
```

### Conda를 이용한 ImFact의 part2(KoBERTSeg) 환경 복원 및 세팅

- 원본 모델(`KoBERT`, `GluonNLP`, `MXNet`, `PyTorch 1.8`) 기반 추론 가능
- Windows 호환
- 충돌 없는 패키지 설치
- GPU가 없을 경우 자동으로 CPU 모드로 작동

- Miniconda 설치 확인
```
conda --version
```

- 새 환경 생성
```
conda create -n imfact-legacy python=3.7 -y
```

- 활성화
```
conda activate imfact-legacy
```

- 핵심 패키지부터 “Conda”로 설치
	- GPU 없는 경우 `cudatoolkit`은 빼기
```
conda install pytorch=1.8.1 torchvision=0.9.1 cudatoolkit=11.0 -c pytorch -y
```


- pip 최신화
```
python -m pip install --upgrade pip==21.2.4
```

- KoBERT 관련 라이브러리 “하나씩” 수동 설치
```
pip install --no-deps numpy==1.18.5
pip install --no-deps mxnet==1.7.0.post2
pip install --no-deps gluonnlp==0.10.0
pip install --no-deps transformers==4.18.0
pip install --no-deps sentencepiece==0.1.94
pip install --no-deps scikit-learn==0.23.2
pip install --no-deps tqdm==4.31.1
pip install --no-deps onnxruntime==1.8.0
pip install --no-deps git+https://github.com/SKTBrain/KoBERT.git@47a69af87928fc24e20f571fe10c3cc9dd9af9a3
```

- 환경 저장
```
conda env export --no-builds > environment_windows.yml
```

- 추후 재생성
```
conda env create -f environment_stable.yml
```

### KoBERT 토크나이저 패키지 별도 분리 문제

- SKTBrain의 KoBERT GitHub 리포지토리에서 KoBERT-Tokenizer가 삭제됨
- KoBERT 내부의 tokenizer를 직접 사용하는 방법으로 대체
```python
# 변경 전
# from kobert_tokenizer import KoBERTTokenizer

# 변경 후
from kobert.pytorch_kobert import get_pytorch_kobert_model
from kobert.utils import get_tokenizer
```

```python
# 변경 전
tokenizer = KoBERTTokenizer.from_pretrained("skt/kobert-base-v1")

# 변경 후
_, vocab = get_pytorch_kobert_model()
tokenizer = get_tokenizer()

```


### Linux 환경에서 환경 복원

- `environment.yml` 사용 가능 (충돌 없음)
- `--no-deps` 옵션 불필요
- CUDA 자동 인식
- ImFact part2 모델(`KoBERTSeg`) 즉시 추론 가능

### EC2 생성

- AMI
	- Deep Learning OSS Nvidia Driver AMI GPU PyTorch 2.8 (Ubuntu 24.04)

- AWS EC2 vCPU 할당량 증가 요청
	- 16 요청
```
Running On-Demand G and VT instance
```

### Colab으로 실험

- Tokenizer가 제대로 작동하지 않음

