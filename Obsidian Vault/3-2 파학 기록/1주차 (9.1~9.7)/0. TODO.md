
- 이때까지 한 것 및 아래 계획 반영해서 일정 및 계획 조정
- 모델 예측 수행까지 하기
- 지라 수정
---

## 계획

### EC2에 모델 소스 코드 업로드 및 분석
- 디렉토리 정리 (data 폴더 생성 등)
- 도커 컨테이너 실행 및 코드 실행
	- EC2 + Docker
- 데이터셋 로드, 전처리 모듈, 토크나이즈 부분 코드 확인
	- KoNLPy·Pandas 기반 전처리 모듈
	- 토큰화·정규화·불용어 처리 스크립트
- 크롤링한 데이터를 로드, 전처리, 정제하는 방법 확인
	- 빅카인즈 vs 뉴스토어 vs 크롤링
	- Hugging Face 토크나이저
	- 입력 포맷
	- 샘플 토크나이즈
- 학습된 모델을 사용하여 예측을 수행하는 방법 확인
- 신뢰도 점수 산출 방안 및 그에 따른 코드 수정 및 파인튜닝 방안 제고
	- 분류 모델 (HAND) -> 낚시성 기사 가능 점수 산출 모델로 파인튜닝
	- 주제 분리 탐지 모델 (BERT) -> 본문 내에서 화제변환 여부, 화제 수 등의 정보를 산출하여 낚시성 기사 가능 점수 산출 모델로 파인튜닝
	- 두 모델을 모두 사용하여 예측
	- 둘 중 하나라도 낚시성 기사라고 예측할 경우 해당 예측을 수용 및 해당 점수 제공
	- 모두 낚시성 기사라고 예측할 경우 두 예측을 모두 수용 및 두 개의 점수 모두 제공
---
### 모델 파인튜닝
- 기존 코드에서 모델 파인튜닝 가능 여부 확인
	- 처음부터 모델 코드를 작성하는 것의 현실성 확인
	- 베이스라인 모델로 잡고 파인튜닝
		- 한국어 Word Embeddings
	- 추가적인 파인튜닝 및 최적화는 AWS에서 데이터 배치 및 모델 서빙/예측, FastAPI 연동의 전 과정이 끝난 후 다시 시작
---
### DB(S3) 구축 및 크롤링
- DB 구축 및 크롤링 코드 작성
- 데이터 정제 코드 작성
- 모델 예측 수행 코드 작성
- 대규모 데이터 배치 및 모델 예측 수행 가능 여부 확인
- 대규모 데이터 모델 예측 수행 코드 작성
---
### API 구축
- AWS S3를 이용한 뉴스 기사 데이터 DB 구축
- FastAPI 연동 및 모델 서빙
- 모델 예측 수행 결과를 DB에 저장하는 로직 작성
---
- AWS로 모든 코드 이전
	- Fargate
	- Lambda
	- 크롤러 이미지 (ECR)
	- 크롤링 (Scrapy / scrapy-playwright)
	- 임베딩 배치 (SageMaker Processing)
	- OpenSearch
---
- AWS에서 스케줄링을 통해 크롤링 및 모델 예측 자동화
---

## 추후

- 뉴스 기사 요약 모델 연동 (OpenAI GPT-4 / Hugging Face Bart)
- Bedrock 래퍼
- 비동기 요약 API (LangChain+AsyncIO)
---
- 배치 스케줄링 (EventBridge)
- 오케스트레이션 (Step Functions)
---
- 분산 학습 환경 (PyTorch Lightning + Accelerate/DeepSpeed)
---
- ECR/ECS 연동
- AWS CodeDeploy/EC2 Canary 배포
---
- 오토스케일 (Cluster Autoscaler)
- 성능 모니터링 대시보드 구축 (Prometheus, Grafana)