# ğŸ“˜ **2ë‹¨ê³„ ì „ì²´ ëª©í‘œ**

âœ” 1) í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬(cleaning)  
âœ” 2) ë¬¸ì„œ chunking (ìë¥´ê¸°)  
âœ” 3) ë¬¸ì„œ ingestion API(/ingest) êµ¬ì¡° ë§Œë“¤ê¸°  
âœ” 4) ì‹¤ì œë¡œ í„°ë¯¸ë„ì—ì„œ ingestion test ìˆ˜í–‰

ì´ì œ í•˜ë‚˜ì”© ê°€ë³´ì.

---

# â­ Step 2-1 â€” íŒŒì¼ ìƒì„±í•˜ê¸°

backend/app/services í´ë”ê°€ í•„ìš”í•˜ë¯€ë¡œ ì•„ë˜ì²˜ëŸ¼ ë§Œë“¤ê¸°:

```bash
mkdir -p backend/app/services
mkdir -p backend/app/utils
mkdir -p backend/app/models
mkdir -p backend/app/routers
```

í´ë”ê°€ ì¤€ë¹„ë˜ë©´ ì½”ë“œ íŒŒì¼ì„ ì¶”ê°€í•  ìˆ˜ ìˆì–´.

---

# â­ Step 2-2 â€” í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬(text_cleaning.py)

**í•„ìˆ˜ ê¸°ëŠ¥:**

- ì¤„ë°”ê¿ˆ ì •ë¦¬
- ê³µë°± ì œê±°
- ë¶ˆí•„ìš”í•œ whitespace ì œê±°

ğŸ“ `backend/app/utils/text_cleaning.py` íŒŒì¼ ìƒì„±:

```python
import re

def clean_text(text: str) -> str:
    if not text:
        return ""

    text = text.replace("\n", " ").replace("\t", " ")
    text = re.sub(r"\s+", " ", text).strip()
    return text
```

---

# â­ Step 2-3 â€” Chunking ê¸°ëŠ¥ êµ¬í˜„ (chunker.py)

ë¬¸ì„œë¥¼ 300~500ì ë‹¨ìœ„ë¡œ ì˜ë¼ì£¼ëŠ” ê¸°ëŠ¥ì„ ë§Œë“ ë‹¤.

ğŸ“ `backend/app/services/chunker.py` íŒŒì¼ ìƒì„±:

```python
from app.utils.text_cleaning import clean_text

def chunk_text(text: str, chunk_size: int = 400, overlap: int = 50):
    """
    ê¸¸ì´ê°€ ê¸¸ë©´ chunk_size ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê³ ,
    chunk ê°„ì—ëŠ” overlap ë§Œí¼ ê²¹ì¹˜ê²Œ í•œë‹¤.
    """
    text = clean_text(text)

    chunks = []
    start = 0

    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]

        chunks.append(chunk)

        # ë‹¤ìŒ chunkëŠ” overlapë§Œí¼ ê²¹ì¹˜ê²Œ ì´ë™
        start = end - overlap

    return chunks
```

### âœ” chunking ì˜ˆì‹œ

í…ìŠ¤íŠ¸ê°€ 1000ìì´ê³  chunk_size=400, overlap=50ì´ë©´:

- 0~400
- 350~750
- 700~1100

ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ë˜ë„ë¡ êµ¬ì„±ë¨.

---

# â­ Step 2-4 â€” ingestion ìŠ¤í‚¤ë§ˆ(models)

ì‚¬ìš©ìê°€ `/ingest` APIë¡œ ë¬¸ì„œë¥¼ ë³´ë‚¼ ë•Œ ì‚¬ìš©ë  ë°ì´í„° ì •ì˜.

ğŸ“ `backend/app/models/schemas.py` íŒŒì¼ì— ì•„ë˜ ë‚´ìš© ì¶”ê°€:

```python
from pydantic import BaseModel

class IngestRequest(BaseModel):
    source: str                 # íŒŒì¼ ì´ë¦„ ë˜ëŠ” ë¬¸ì„œ ì¶œì²˜
    text: str                   # ë¬¸ì„œ ì „ì²´ í…ìŠ¤íŠ¸
```

---

# â­ Step 2-5 â€” ingestion ì„œë¹„ìŠ¤(ingestion.py)

ğŸ“ `backend/app/services/ingestion.py` íŒŒì¼ ìƒì„±:

```python
from app.services.chunker import chunk_text
from app.services.embedding import get_embedding    # 3ë‹¨ê³„ì—ì„œ êµ¬í˜„ ì˜ˆì •
from app.services.qdrant_client import QdrantDB     # 4ë‹¨ê³„ì—ì„œ êµ¬í˜„ ì˜ˆì •

def ingest_document(source: str, text: str):
    chunks = chunk_text(text)

    payloads = []
    for idx, chunk in enumerate(chunks):
        payloads.append({
            "id": f"{source}-{idx}",
            "text": chunk,
            "metadata": {
                "source": source,
                "chunk_id": idx
            }
        })

    return payloads
```

â­ ì£¼ì˜  
ì—¬ê¸°ì„œëŠ” ì•„ì§ embeddingê³¼ Qdrant ì €ì¥ì„ ì‹¤ì œë¡œ ì—°ê²°í•˜ì§€ ì•Šì•„.  
**â€œchunk ë¦¬ìŠ¤íŠ¸ ìƒì„±ê¹Œì§€â€**ê°€ 2ë‹¨ê³„ ëª©í‘œì´ê¸° ë•Œë¬¸.

Embedding + Qdrant ì €ì¥ì€ **3ë‹¨ê³„ì—ì„œ ì™„ì„±**ë¨.

---

# â­ Step 2-6 â€” `/ingest` API ë§Œë“¤ê¸°

ğŸ“ `backend/app/routers/ingest.py` íŒŒì¼ ìƒì„±:

```python
from fastapi import APIRouter
from app.models.schemas import IngestRequest
from app.services.ingestion import ingest_document

router = APIRouter()

@router.post("/ingest")
def ingest(req: IngestRequest):
    chunks = ingest_document(req.source, req.text)
    return {
        "message": "Document chunked successfully",
        "total_chunks": len(chunks),
        "chunks_preview": chunks[:3]   # ì• 3ê°œë§Œ í™•ì¸ìš©
    }
```

---

# â­ Step 2-7 â€” main.pyì— router ì—°ê²°

ğŸ“ `backend/app/main.py` ìˆ˜ì •:

```python
from fastapi import FastAPI
from app.routers import ingest

app = FastAPI()

app.include_router(ingest.router)

@app.get("/")
def health():
    return {"status": "ok"}
```

---

# â­ Step 2-8 â€” Docker ì´ë¯¸ì§€ ë‹¤ì‹œ ë¹Œë“œ & ì‹¤í–‰

ë£¨íŠ¸ í´ë”ì—ì„œ:

```bash
docker compose down
docker compose up --build -d
```

---

# â­ Step 2-9 â€” Ingestion ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

ë¸Œë¼ìš°ì € ë˜ëŠ” Postmanì—ì„œ:

POST [http://localhost:8000/ingest](http://localhost:8000/ingest)

Body(JSON):

```json
{
  "source": "sample_doc",
  "text": "ì—¬ê¸°ì— ì›í•˜ëŠ” ê¸´ ë¬¸ì„œë¥¼ ë„£ì–´ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”. ë¬¸ì¥ì´ ê¸¸ìˆ˜ë¡ chunkê°€ ì—¬ëŸ¬ ê°œ ìƒê¹ë‹ˆë‹¤..."
}
```

ì˜ˆìƒ ì‘ë‹µ:

```json
{
  "message": "Document chunked successfully",
  "total_chunks": 3,
  "chunks_preview": [
    {
      "id": "sample_doc-0",
      "text": "ì—¬ê¸°ì— ì›í•˜ëŠ” ê¸´ ...",
      "metadata": { "source": "sample_doc", "chunk_id": 0 }
    },
    ...
  ]
}
```

ì´ ì‘ë‹µì´ ë‚˜ì˜¤ë©´ **2ë‹¨ê³„ ì™„ì„±!**

---

# ğŸ‰ 2ë‹¨ê³„ê°€ ëë‚˜ë©´ ë¬´ì—‡ì´ ì¤€ë¹„ëœ ìƒíƒœì¸ê°€?

ì™„ë£Œ í›„ì—ëŠ”:

- í…ìŠ¤íŠ¸ â†’ chunk ë¦¬ìŠ¤íŠ¸ ë³€í™˜ ì„±ê³µ
- ë¬¸ì„œë¥¼ Qdrantì— ì €ì¥í•  ì¤€ë¹„ ì™„ë£Œ
- `/ingest` APIë¡œ ë¬¸ì„œë¥¼ ë°›ì•„ chunking ê°€ëŠ¥

ì´ì œ ë°ì´í„°ê°€ ì¤€ë¹„ëê³ ,  
ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ë²¡í„°í™”(embedding)ì™€ Qdrant ì €ì¥ì„ ì¶”ê°€í•˜ë©´  
ì§„ì§œ ë¬¸ì„œ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì™„ì„±ë¨.

---

# ğŸ”œ ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´(3ë‹¨ê³„)

3ë‹¨ê³„ì—ì„œëŠ”:

- OpenAI embedding ë˜ëŠ” sentence-transformers embedding ì—°ê²°
- chunkë§ˆë‹¤ ë²¡í„° ìƒì„±
- Qdrant ì»¬ë ‰ì…˜ ìƒì„± + ë²¡í„° ì €ì¥ êµ¬í˜„

ì¦‰, **ë²¡í„°DBì— ë¬¸ì„œë¥¼ ì‹¤ì œë¡œ ë„£ëŠ” ì—”ì§„ì„ ì™„ì„±í•˜ëŠ” ë‹¨ê³„**ì•¼.

---
---

### ì½”ë“œ ìˆ˜ì • í›„ Docker ì´ë¯¸ì§€ ë‹¤ì‹œ ë¹Œë“œ & ì‹¤í–‰
```shell
docker compose down
docker compose up --build -d
```

---

## âœ” ë°©ë²• 1 â€” Swagger UIì—ì„œ POST í˜¸ì¶œ

ë¸Œë¼ìš°ì €ì—ì„œ:

ğŸ‘‰ [http://localhost:8000/docs](http://localhost:8000/docs)

ì´ë™ í›„:

1. `/ingest` ì„¹ì…˜ í´ë¦­
2. â€œTry it outâ€
3. JSON ì…ë ¥ í›„ â€œExecuteâ€

ì´ë ‡ê²Œ í•˜ë©´ POST ìš”ì²­ìœ¼ë¡œ ì²˜ë¦¬ë˜ì–´ ì„±ê³µí•¨.

---

## âœ” ë°©ë²• 2 â€” Postman ì‚¬ìš©

POST ë©”ì„œë“œë¡œ:

```
POST http://localhost:8000/ingest
```

Body(JSON):

```json
{
  "source": "sample",
  "text": "ì´ê²ƒì€ chunking í…ŒìŠ¤íŠ¸ìš© ë¬¸ì„œì…ë‹ˆë‹¤."
}
```

---

## âœ” ë°©ë²• 3 â€” curlë¡œ í…ŒìŠ¤íŠ¸

í„°ë¯¸ë„ì—ì„œ:

```bash
curl -X POST "http://localhost:8000/ingest" \
  -H "Content-Type: application/json" \
  -d "{\"source\": \"sample\", \"text\": \"Hello World Test\"}"
```

---
