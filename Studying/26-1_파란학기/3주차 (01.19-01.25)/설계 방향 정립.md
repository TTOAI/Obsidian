- 주제 의식
	- AI는 인간의 개입 없이 개발 사이클 전체를 안정적으로 닫을 수 있는가?

- 기존 코딩 에이전트
	- 테스트/검증은 보조적임
		- `테스트/검증이 보조적으로 제공되는 에이전트가 있는가? 혹은 시스템 내부에서 테스트/검증이 이루어지는가?`
	- 코드 생성과 평가가 동일한 맥락(context)에 노출되어 있음
	- 실패의 원인, 수렴 여부, 신뢰성에 대한 체계적인 분석을 제공하지 않음
		- `수렴 여부는 어떻게 확인할 것인가?`
		- `체계적인 분석 제공 -> 실패 코드, 어떻게 실패했는지, 왜 실패했는지, 어떻게 고치는지, 수정 이후에 고쳐졌는지, 다른 테스트와는 독립적으로 이루어졌는지, 성공했던 테스트가 다시 실패하지 않는지, 최종적으로 모든 요구사항을 만족하는지 등`

- 문제 의식
	- 코드를 얼마나 잘 짜는가 (X)
	- AI 개발 자동화가 언제, 왜, 어떻게 실패하는가를 설명할 수 있는가 (O)

- 프로젝트 목표
	- 개발 사이클 자동화의 한계와 가능성 검증
	- 단순 성공/실패가 아니라 수렴 여부와 반복 특성을 관찰
		- `수렴 여부는 어떻게 판단할 것인가?`
		- `반복 특성이란 무엇인가?`
	- 신뢰 가능한 자동화의 조건 정의
		- 테스트 기반 검증, 실패 통제, 중단 조건(stopping criteria)을 통해 무한 루프·환각·편향을 제어할 수 있는 구조를 설계
			- `실패 통제와 중단 조건은 어떻게 설계할 것인가?`
			- `무한 루프 제어 -> limit?`
			- `환각은 어떻게 통제할 것인가? -> 테스트 기준을 정립하거나, 코드 유형별 테스트 기법 표준을 도입하여 RAG 기반 결과 도출?`
			- `편향은 어떻게 측정하는가? 어디에 편향되었다는 것의 기준이 무엇인가?`
		- "돌아가는 코드"가 아닌 검증된 결과를 기준으로 자동화 판단
			- `검증된 결과란 무엇인가? 결과를 어떻게 검증할 것인가?`
	- 비교·평가 가능한 실험 시스템 구축
		- 특정 도구/모델에 종속되지 않고 모델·런타임·오케스트레이션을 교체 가능한 구조로 설계
		- 구조 차이에 따른 성능·신뢰성 차이를 실험적으로 비교
			- `성능을 어떤 기준으로 측정할 것인가?`
			- `신뢰성을 어떤 기준으로 측정할 것인가?`

