
## 1) 문제 정의

### 현장에서 실제로 발생하는 문제와 니즈

- 구인구직 스캠의 ‘회색지대’ 문제가 커지고 있음
    - DM/오픈채팅/텔레그램/인스타/트위터 등에서 “고수익·간단업무·대리업무” 형태로 유입
    - 링크(구글폼/노션/외부 사이트)로 이동시키고 개인정보·계좌·인증 등을 요구

- 피해자는 종종 “확신이 없어서” 도움 요청을 못 함
    - 경찰 신고: 무겁고 절차 부담
    - 커뮤니티 문의: 노출 부담 / 답변 품질 편차
    - 주변인 상담: 상황 설명 비용이 큼(캡처·정리·맥락 설명)

### 해결해야 하는 대상(타겟)

- 1차 타겟: 청년층/사회초년생/단기 알바 탐색자
- 2차 타겟: 이직 준비자, 프리랜서, 부업 탐색자
- 공통 특성: "이상하긴 한데 사기라고 단정하긴 애매한 제안"을 자주 접함 + 빠른 판단이 필요

### 문제의 중요성/발생 배경

- 구직 채널이 공식 공고(채용 사이트)에서 DM/메신저 기반 제안으로 확장되며 검증 장치가 약해짐
- 스캠은 기술적으로도 정교해져서(그럴듯한 회사 소개, 포트폴리오 링크, 가짜 후기) 초기만 보면 정상처럼 보이는 경우가 많음
- 결과적으로 "사기인지 아닌지"가 아니라, 지금 어떤 행동을 하면 위험이 커지는지를 알려주는 게 핵심 니즈

### KPI(서비스 성과 지표) — 해결 후 기대 변화 

정량 KPI
- (KPI1) 위험 제안에 대한 '개인정보 제공/외부 메신저 이동/선입금' 행동 감소율
- (KPI2) 사용자 행동 가이드 실행률
    (예: "추가 질문 템플릿 사용", "차단/무시 선택", "신고/제보 링크 이동")
- (KPI3) "의심 제안 검증"까지의 평균 소요시간 단축 (예: 3분 내)
- (KPI4) 반복 신고/제보 누적 시 동일 패턴 재노출 감소

정성 KPI
- “의심 순간에 바로 쓸 수 있다”는 접근성/심리적 장벽 감소
- 사용자가 스스로 판단할 수 있는 기준을 학습하여 유사 상황 재발 방지

---

## 2) 솔루션 개요

- 의심되는 구인 제안(메시지/링크/캡처)을 넣으면, AI가 '위험 신호'와 '확인 질문'을 만들어주고, 사용자가 안전한 행동을 선택하도록 돕는 판단 보조 서비스
- 탐지가 아닌 판단(근거/주의점/다음 행동) 중심 서비스

---

### 전체 구조

1. 입력
	- `공유하기` 버튼을 통한 텍스트(복붙), 링크(URL), 캡처 이미지 전달
	- 상황을 직접 설명할 필요 없음

2. 분석
	- 콘텐츠 구조 파싱(모집/업무/보상/요구사항/링크 목적/연락 수단 등)
	- 위험 신호 탐지(패턴+LLM)
		- `키워드 및 패턴 추출 → 임베딩 기반 유사도 매칭 → RAG + LLM`
		- `위험 패턴 참고 문서 및 데이터`
			- `경찰청·금융감독원 보이스피싱 사례`
			- `언론 보도된 구직 사기 기사`
			- `내부 생성 데이터`
	- 유사 사례 패턴 매칭
		- `위와 동일`

3. 행동 설계
	- 사용자가 상대에게 던질 검증 질문 템플릿 생성  
	    ("계약서 제공 가능한가요?", "사업자등록/회사주소 확인 가능?", "선입금/인증 요구 사유?", "업무 범위/정산 조건 문서화?" 등)
		- `무엇을 기반으로, 무엇을 근거로 효과적인 검증 질문을 생성할 것인가?`
		- `관련 데이터는 어디서 구할 것인가?`
	- 상황별 추천 행동:  
	    계속 대화 / 질문 후 판단 / 즉시 중단 / 차단 / 신고·제보
	    - `상황 및 상황별 추천 행동을 케이스별로 구체적으로 나눌 필요가 있어보임`
	    - `상황별 추천 행동은 무엇으로 기반으로 정할 것인가?`

4. 리포트
	- “사기입니다/아닙니다” 단정 대신:
	    - 주의해야 할 요소 Top N
		    - `무엇을 기반으로 정할 것인가?`
		    - `관련 데이터를 어디서 가져올 것인가?`
	    - 정상 구직과 다른 지점
		    - `업종별 정상 구직 프로세스`
			    - `공통적인 정상 프로세스 정하기`
			    - `플랫폼, 업종별로 확장 가능성 언급`
	    - 지금 단계에서의 위험 행동(하면 안 되는 것)
		    - `무엇을 기반으로 정할 것인가?`
		    - `관련 데이터를 어디서 가져올 것인가?`
	    - 다음 액션 체크리스트

5. 패턴 누적
	- 사용자 익명 제보를 패턴화(문구, 링크 유형, 요구 흐름)
		- `구체적으로 어떻게 패턴화를 시킬 것인가?`
	- 동일/유사 패턴 재등장 시 경고 강도 강화
		- `패턴 구조?`
		- `경고 강도 기준`
			- `유사 패턴 케이스 수`
			- `최근 신고 빈도수`

---

### 솔루션 전체 시나리오

1. 사용자가 관심이 가는 구인구직 공고를 보거나 DM을 받음 → 애매하거나 찝찝함
2. 앱으로 공유
3. AI가 "위험 신호"와 "검증 질문 세트"를 제공
4. 사용자는 질문을 던져 확인
	- `답변을 이미지, 텍스트 형태로 입력`
	- `결과 리포트를 위한 충분한 정보가 쌓일 때까지 검증 질문 제공 및 재질문 유도`
5. 재질문을 통해 구체적인 상황 파악
6. 결과 리포트에서 "위험 요소 / 추천 행동" 제공
7. 유사 패턴이 누적되면 다른 사용자에게도 더 빠르게 경고

---

## 3) 데이터 기술 및 활용 (Data & Tech)

### 데이터 종류

- 사용자 입력 데이터
	- 메시지 텍스트(공고/제안 내용)
	- 링크(URL)
	- 캡처 이미지
	- 대화 일부(사용자 붙여넣기 혹은 캡처)

- 수집한 외부 데이터
	- 구인구직 스캠 사기 실제 사례
	- 관련 뉴스 기사

- 내부 패턴 누적 데이터
	- 위험 시그널 벡터(요구 흐름, 링크 도메인 유형, 문구 템플릿)
	- 동일 패턴 출현 빈도

---

### 데이터 처리 방식

- 텍스트:
    - 정규화(특수문자/띄어쓰기/반복문구)
    - 구조 추출(업무, 보상, 요구사항, 채널 이동, 시간 압박 표현 등)
- 링크:
    - 도메인/경로/쿼리 분석(단축URL 여부, 리다이렉트 여부 등 MVP에서는 정적 분석 중심)
    - `링크 유형을 구분 및 분석 프로세스 구체화(선택)`
    - `가짜/사기 링크인지 판별(선택)`
    - `링크 내 데이터 크롤링 및 구인구직 공고 관련 내용 수집`
    - `크롤링 규칙 및 수집할 데이터 유형 구체화가 필요해보임`
- 캡처:
    - OCR(옵션)로 텍스트 추출 후 동일 파이프라인 적용
        ※ OCR은 품질 이슈가 있어 "선택 기능"으로 두는 게 안전
        - `성능 좋은 OCR 옵션`
	        - `VILA`
	        - `Google Vision OCR`
	        - `Naver CLOVA OCR

---

### 모델/라이브러리/도구

- LLM API: 요약 + 위험 신호 근거 생성 + 검증 질문 생성 + 리포트 작성
- 룰 기반 스코어링: 단순하지만 설명력 좋음
    (예: 위험 시그널 가중치 합산 → Low/Medium/High)
- 저장: 익명화된 로그/패턴
	- `스토리지에 저장 및 주간/일간 배치`
	- `집계 결과를 대시보드를 통해 경찰/기관에 제공`

---

### 기술적 제약 및 해결 전략

제약 1) “가짜 계정으로 대신 접근”은 약관/윤리 리스크
- 해결: 대화 ‘대리 수행’이 아니라 '대화 전략/질문 생성'으로 설계를 전환
- 서비스는 사용자가 직접 묻도록 가이드(주체성 유지, 법적 리스크 최소화)

제약 2) '사기/안전' 단정은 법적·책임 리스크
- 해결: 단정 금지, 근거 중심 리포트
    - "위험 신호"와 "확인 질문" 중심
    - 서비스는 보조, 사용자가 최종 판단

제약 3) 개인정보 처리 민감
- 해결:
    - 사용자의 최소 입력(복붙 텍스트만으로도 가능)
    - 익명화/마스킹(전화번호·계좌·주민번호 유사 패턴 자동 마스킹)
    - 저장은 opt-in(정보 제공 동의 받기), 또는 통계용 특징량만 저장

---

## 4) 사용자 시나리오/유즈케이스

### 주요 사용자
- 구직자: 의심되는 공고를 보거나 제안을 받은 사람
- 경찰/기관: 관련 데이터 통계 필요

---

### 사용자 행동 흐름

1. 사용자가 DM/오픈채팅에서 구인 제안을 받음
2. 찝찝하지만 신고하기엔 애매 → 공유를 통해 서비스 접속
3. 입력:
    - 메시지 텍스트 붙여넣기, 링크 입력, 캡처 이미지 삽입
4. 결과 화면(리포트):
    - 위험 신호 Top N
    - 정상 구직과 다른 지점
    - 지금 하면 위험한 행동(예: 선입금/인증/개인정보)
5. 검증 질문 버튼:
    - 복사하기로 상대에게 질문 보내기
6. 사용자가 답변을 받으면(선택):
    - 답변 내용 추가 입력 → 리포트 업데이트
7. 최종 행동 선택:
    - 지원 중단/차단/무시
    - 신고/제보 링크 이동(가벼운 제보부터)

---

## 5) 기대 효과 및 향후 확장성 (Expected Impact)

### 현장에서 기대되는 효과

- 정량 효과
	- 사기 위험이 높은 케이스에서 개인정보 제공/선입금 진행률 감소
	- 검증 질문 템플릿 사용으로 사기 본색 노출률 증가
	- "의심 → 확인"까지 평균 시간 단축

- 정성 효과
	- "신고 부담"이 아니라 "가벼운 확인"부터 시작함으로써 행동 장벽 낮춤
	- 사용자가 반복 경험을 통해 스스로 판별 기준을 학습
	- 커뮤니티/기관 도움 전 단계에서 사전 예방 레이어 역할

---

### 확장 가능성 및 고도화

- 패턴 데이터 축적: "유행 스캠 템플릿" 업데이트
- 브라우저/메신저 공유 UX 강화: "공유 → 우리 서비스로 보내기"
- 기관/플랫폼 연계:
    - 경찰/지자체/플랫폼에 "익명 통계 대시보드" 제공(실시간은 부담되면 주간 리포트로)
- 다른 회색지대 사기 도메인 확장:
    - 중고거래, 투자권유, 대출, 로맨스 스캠, 사칭/협박형 등  
    - 신고/확신이 어려운 단계에서의 판단 보조 가능
- 사용자 피드백("실제로 사기였음/아니었음")을 통한 위험 신호 가중치 보정

---

## 할 것

- OCR 모델 선택
	- 입력 유형
		- 채팅 캡처 이미지
		- 공고 이미지 혹은 스크린샷
	- 목적: 위험 신호 추출이 가능한 최소 텍스트 확보
	- https://devocean.sk.com/experts/techBoardDetail.do?ID=165524
	- `VILA`
	- `Google Vision OCR`
	- `Naver CLOVA OCR` (V)

- 크롤링해야 할 데이터 정하기
	- 사용자가 사용하는 플랫폼 종류
	- 업종
	- 회사 정보
	- 업무 내용
	- 요구사항

- LLM의 판단에 참고하기 위해 수집해야 할 외부 데이터 목록
	- 구인구직 스캠 실제 사례

- 데이터 정제 및 가공을 통해 만들어야 할 데이터셋 및 테이블 
	- 과거 사례 요약 데이터
	- 위험 키워드 데이터

- 상황별, 시나리오 단계별 LLM 답변 규칙/룰 정립

- LLM가 생성하는 리포트에 들어갈 내용 정하기
