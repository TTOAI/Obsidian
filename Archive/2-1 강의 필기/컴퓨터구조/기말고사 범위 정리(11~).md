
----
### 11. Floating Point Arithmetic
----
- fixed-point notation
	![[Pasted image 20240606144328.png]]
	- binary point 사용

- IEEE floating point (single-precision floating point)
	![[Pasted image 20240606144739.png]]
	- sign bit: 1bit (0: non-negative, 1: negative)
	- exponent: ==8bits==, actual exponent + ==127==
	- fraction: 23bits

- IEEE floating point 구분 (single-precision floating point)
	- exponent = 0, fraction = 0
	  -> 0
	- exponent = 0, fraction = nonzero
	  -> denormalized number
		- 절댓값이 아주 작은 수를 표현
		- exponent는 ==-126==으로 고정
		- sinificand의 정수부는 0
	- exponent = 0b11..11, fraction = 0
	  -> +-infinity
	- exponent = 0b11..11, fraction = nonzero
	  -> NaN(Not a Number)

- smallest absolute value
	- exponent = 0b00000001, fraction = 0b00..00
	- ==+-1.0 * 2^(-126)==

- largest absolute value
	- exponent = 0b11111110, fraction = 0b11..11 $\approx$ 2
	- ==+-2.0 * 2^127==

- double-precision floating point
	- sign bit: 1bit, exponent: ==11bits==, fraction: 52bits
	- exponent = actual exponent + ==1023==

- 16bit representation
	- float16
		- sign bit: 1bit, exponent: ==5bits==, fraction: 10bits
	- Bfloat16
		- sign bit: 1bit, exponent: ==8bits==, fraction: 7bits

- FP addition
	- exponent 큰 쪽으로 맞춤
	- significand 더함
	- normalize, overflow 확인

- FP multiplication
	- exponent 더함
	- significand 곱함
	- normalize, overflow 확인

- FP Instructions in MIPS
	- instruction의 길이가 서로 다르면 가장 오래 걸리는 것 기준으로 회로를 디자인함
	- FP연산 같은 instruction들은 프로그램에서 거의 쓰지 않음
	- 몇 안 되는 instruction 때문에 회로가 비효율적으로 디자인되는 것을 막고 싶음
	- 오래 처리해야 하는 instruction들을 따로 빼서 별도의 회로 구성을 만듦
	  ↓
	- coprocessor 1: FP hardware
----
### 12. Processor - Datapath and Control
----
- logic design basics
	- Combinational elements
		- 이전 신호와 상관없이 현재 들어온 신호에 따라 결과를 반환함
		- state elements로부터 받은 신호의 데이터를 가지고 연산함
		- ex) and-gate, adder, multiplexer, arithmetic/logic unit
	- State (sequential) elements
		- 값이 저장되어 있음
		- 이전 값을 반영해서 현재 들어오는 값을 새로운 값으로 변환함
		- ex) register
		- Edge-triggered: Update when Clk changes from 0 to 1

- Clocking Methodology
	- Longest delay determines clock period

- datapath
	- Elements that process data and addresses in the CPU
----
### 13. Pipelining
----
- Pipeline Performance
	- The stage taking the longest time determines the overall ==throughput==
	- ==Speedup== due to increased ==throughput==
		- ==Latency== (time for each instruction) does not decrease
----
### 14. Pipeline Hazards
----
- Pipeline Hazards:
	  모종의 이유로 다음 instruction의 수행을 막게 되는 상황
	-  hazard가 해결될 때까지 다음 instruction의 수행을 막음(stall the pipeline)
	  -> performance가 낮아짐
	- 회로를 수정해서 pipeline stall을 해결할 수 있으면 수정함
	
	- Structure hazards
		- ID, WB 단계에서 register 사용이 겹침
			각 단계를 반으로 쪼개서 1 cycle동안 WB->ID 순으로 register에 접근하도록 함
		- IF, MEM 단계에서 메모리 사용이 겹침
			instruction, data를 위한 두 port를 사용해서 메모리 접근
	
	- Data hazards
		: 이전 instruction에 의해 값이 바뀌는 register를 사용함
		1. Read-after-Write (RAW), (true) dependency
			: pipeline을 ==2 cycle stall==해서 이전 instruction이 WB을 수행할 때 ID를 수행함
			- sturucture hazards 해결 안 했으면 ==3 cycle stall== 해야 함
		2. forwarding, bypassing
			: datapath에 connections를 추가해서 바로 쓸 수 있도록 함
			- ALU instruction
				- 이후 2개의 instruction에 대해서만 확인
				- EX/MEM에서 EX로, MEM/WB에서 EX로 forwarding
				- ==stall 없음==
			- lw
				- 이후 1개의 instruction에 대해서만 확인
				- MEM/WB에서 EX로 forwarding
				- ==1 cycle stall==
				  -> lw에 의해 값이 바뀌는 register를 바로 다음 instruction에 사용하지 않도록 instructions를 재배치함으로써 stall 해결 가능
	
	- Control hazards
		: branch에 의해 생기는 hazards
		1. branch outcome(decision + target address)이 결정되기 전까지 stall함 
			- branch outcome이 MEM stage에서 결정되므로 MEM stage에서 pc값이 바뀐 후 그 다음 cycle부터 instruction fetch가 다시 가능함
			  -> ==3 cycle stall==
	
	- Data Hazards for Branches
	  : branch outcome을 ID stage에서 결정함으로써 생기는 data hazards
		- ALU instruction 다음 branch
		  -> ==1 cycle stall== 후 EX/MEM에서 ID로 forwarding
		- lw 다음 branch
		  -> ==2 cycle stall== 후 MEM/WB에서 ID로 forwarding
		- branch 이후
		  -> ==1 cycle stall==
----
### 15. Branch Prediction
----
- branch prediction
	- Static branch prediction
		- branch를 만났을 때 주변의 상황과 관계 없이 prediction을 함
		- MIPS pipeline
			: not taken을 기본으로 하는 static branch prediction 사용
	
	- Dynamic branch prediction
		- hardware가 실제 branch의 behavior를 측정해서 future behavior를 가정함
		- deeper and superscalar pipelines에서는 branch penalty가 크므로 modern architectures에서는 dynamic prediction을 사용
	
	- prediction이 맞든 틀리든 pipeline의 correctness와는 관련 없음

- Branch History Table (BHT)
	- branch direction predictor를 구현하기 위해 필요한 표
	
	- PC indexes table of bits (0 = N, 1 = T), no tags
		- PC값에 따라 BHT의 값이 결정됨
	
	- 1-bit predictor
		- 이전 outcome의 결과로 prediction
		- prediction이 틀렸으면 바로 바꿈
		- 문제점: inner loop branches는 first iteration과 last iteration에서 총 두 번의 misprediction을 함
	- 2-bit Saturating Counters (2bc) Predictor
		- (0, 1, 2, 3) = (N, n, t ,T)
		- perdictor가 두 번 틀렸을 때 바꿈

- Branch Target Buffer (BTB)
	- target address를 계산하기 위해서는 무조건 1 cycle stall 해야 함
	- target address를 저장해놓기 위한 BTB
	- 옳지 않은 target address를 가져오면 프로그램이 잘못 돌아갈 수 있기 때문에 옳은 target address인지 확인하기 위한 tag가 필요함

- MIPS는 branch를 not-taken으로 prediction함
	![[Pasted image 20240606193422.png]]
	- 오른쪽이 branch predictor friendly하게 짠 코드

-  branch delay slot
	- branch 이후 항상 실행될 instruction을 위한 공간
	- program에 영향을 주지 않는 instruction을 넣음으로써 stall을 줄여 성능을 향상시킬 수 있음

- superscalar
	- 두 개의 instruction을 한 번에 fetch함 (2-way superscalar)

- out-of-order execution
	- processor가 instruction의 순서를 바꿈
----
### 16. Memory Hierarchy
----
- Memory technology
	- Static RAM(SRAM)
	- Dynamic RAM(DRAM)
		- bit 하나의 정보를 축전기 하나에 저장
		- 축전기가 전자를 누전하므로 내용을 일정 시간마다 재생시켜야 됨

- ==principle of locality==
	- ==temporal locality==
		- 최근에 사용된 item은 곧 다시 사용될 가능성이 있음
	
	- ==spatial locality==
		- 최근에 사용된 item 근처에 있는 item들은 곧 사용될 가능성이 있음

- memory hierarchy
	- block, hit, miss
	- larger blocks
		- spatial locality에 의해서 miss rate가 줄어듦
		- block에서 참조하지 않는 data가 많아져 cache의 효율이 줄어듦 -> pollution이 일어남

- DRAM performance factors
	- row buffer
		- DRAM의 동작 과정에서, 특정 셀에 접근하려면 먼저 해당 셀이 속한 행을 row buffer로 가져와야 함
		- DRAM 뱅크 내에서 특정 행(row)을 읽어들여 이 데이터를 임시로 저장하는 메모리 공간
	
	- synchronous DRAM
		- 명령어에서 지정한 row을 활성화하여 해당 행의 데이터를 row buffer에 로드함
		- 지정된 열(Column) 주소에서 시작하여 연속적인 여러 열의 데이터를 순차적으로 읽거나 씀
		- 한 번의 행 활성화와 열 접근 명령으로 여러 데이터를 전송함
		- 연속적인 데이터 블록을 한꺼번에 전송함으로써 메모리 대역폭을 효율적으로 사용할 수 있음
	
	- DRAM banking
		- memory bank: DRAM 모듈은 여러 뱅크로 나누어지며, 각 뱅크는 독립적으로 동작할 수 있음
		- 여러 뱅크가 동시에 데이터를 전송할 수 있어 전체 메모리 대역폭이 증가함

- 4-word wide memory
	- Miss penalty = 1 + 15 + 1 = 17 bus cycles
	- Bandwidth = 16 bytes / 17 cycles = 0.94 B/cycle

- 4-bank interleaved memory
	- 동시에 각 뱅크의 동일한 주소에 접근 (1cycle)
	- 각 뱅크에서 데이터를 읽어오는 데 1cycle씩 4cycle
	- Miss penalty = 1 + 15 + 4×1 = 20 bus cycles
	- Bandwidth = 16 bytes / 20 cycles = 0.8 B/cycle
----
### 17. Cache Optimization
----
- write hit
	- write-through
		- cache memory에 데이터를 쓰는 동시에 main memory에도 동일한 데이터를 써서 데이터 일관성을 유지함
		- 성능이 떨어짐
	
	- write-back
		- wirte buffer
			- 데이터가 memory에 쓰여질 때까지 write buffer에 임시 저장
		- data-write hit 상황에서, cache block에만 write
			- dirty 비트 사용
			- dirty block이 교체되어야 할 때 memory에 wirte

- write miss
	- write allocation
		- Allocate on miss: fetch the block
		- 블록을 메모리에서 가져와 캐시에 저장하고, 그 다음에 데이터를 갱신
	- Write around: don’t fetch the block
		- 블록을 메모리에서 가져오지 않고, 데이터를 직접 메모리에만 저장
	- write-back 방식에서는
		- Usually fetch the block

- Intrinsity FastMATH
	![[Pasted image 20240608134815.png]]
	- cache를 I-cache와 D-cache로 나눔
	- 256blocks $\times$ 16words(64bytes)/block
	- I-cache: read-only
	- D-cache: write-through or write-back
	- Instruction과 data access가 1cycle에 일어남

 - Associative Caches
	![[Pasted image 20240608140748.png]]
- direct mapped
	![[Pasted image 20240608140703.png]]
	- 하나의 block이 하나의 cache entry를 가짐
- Fully associative
	![[Pasted image 20240608140716.png]]
	- block이 어떤 cache entry에도 들어갈 수 있음
- n-way set associative
	![[Pasted image 20240608140726.png]]
	- 각 set(cache entry)은 n개의 (block) entry로 구성됨
	- block number가 set을 결정함
	- 결정된 set의 모든 entry를 동시에 탐색함

- Replacement Policy
	- Set associative에서
	- hit이면 그냥 업데이트
	- miss면
		- non-valid entry 선호
		- non-valid entry가 없으면
			- Least-Recently Used (LRU)
			- random

- Measuring Cache Performance
	![[Pasted image 20240608145656.png]]
	- actual CPI = base CPI + miss rate $\times$ miss penalty

- Average Memory Access Time
	![[Pasted image 20240608145707.png]]
	- actual CPI $\times$ clock time

- Performance Summary
	- CPU 성능 향상
	- base CPI 감소
	- clock 속도 증가
	  ↓
	- miss penalty, memory stall이 큰 영향 미침
	- cache behavior 설계 중요

- Multilevel Caches
	- primary cache: CPU에 붙어있는 작고 빠른 cache
	- primary cache(L1) miss
	  -> L2 miss
	  -> main memory
	- with just primary cache
	![[Pasted image 20240608154934.png]]
	- miss penalty = memory access time $\div$ clock rate
	- add L-2 cache
	![[Pasted image 20240608160840.png]]

- Software Impact on Cache Performance
	![[Pasted image 20240608162403.png]]
	![[Pasted image 20240608162418.png]]
	- cache friendly하게 sofeware를 만들면 cache performance가 올라감
----
### 18. Virtual Memory
----
- virual memory
	- 프로그램들은 main memory를 공유함
	- 각각의 프로그램이 자신만의 private virtual address space를 가짐
	- VM block = page
	- VM translate miss = page fault
	  -> disk에서 memory 가져옴

- page tables
	![[Pasted image 20240608170542.png]]
	- page table entries(PTEs)
		- page table을 구성하는 각각의 rows
		- VPN(Virtual Page Number)에 의해 index가 매겨짐
		- VPN과 pte가 하나씩 대응되고 PTE에 PPN(Physical Page Number)에 대한 정보가 담겨있음
	- page table register
		- physical memory에서 page table을 가리킴
	- page가 memory에 존재
	  -> PTE가 PPN 저장
	- page가 memory에 존재X
	  -> PTE가 disk의 swap space에 있는 위치를 가리킬 수 있음
	![[Pasted image 20240608170302.png]]

- address translation
	![[Pasted image 20240608170337.png]]

- page fault
	- processor가 excpetion을 일으키면 OS가 handling함
	- disk에서 page가 fetch되어야 함
	- 엄청 오래 걸림
	- OS가 page fault rate를 줄이기 위해 노력함
		- fully associative placement
		- Smart page placement algorithms

- TLB
	- address translation은 여러 번의 memory 참조를 필요로 함 -> 성능에 매우 안 좋음
		- (At least) One to access the PTE
		- Then the actual memory access
	- address translation 결과를 caching
	  -> Translation Look-aside Buffer
	- 실행하는 program이 바뀌면 TLB도 flush되어야 함

- Physically addressed caches
	![[Pasted image 20240608174449.png]]

- Physically addressed caches
	![[Pasted image 20240608174727.png]]
	- 여러 프로세스가 동시에 cache에 block을 가질 수 있음
	- 여러 프로세스가 page를 공유할 수 있음
	- address translation이 중간 단계에 위치하여 비효율적임

- Virtually addressed, virtually tagged caches
	![[Pasted image 20240608174951.png]]
	- cache가 virtual address를 그대로 사용
	- cache hit이 나면 address translation이 필요 없으므로 효율적임
	- homonym problem
		- 각각의 프로세스가 같은 virtual address에 대해 다른 translation을 가짐
		  -> 프로세스가 바뀔 때마다 Cache, TLB 둘 다 flush해야 됨
	- Address synonyms or aliases problem
		- 하나의 프로세스에서 다른 virtual address가 같은 physical address를 가리킬 수 있음
		- 같은 physical address를 가리키는 virtual address들 중 하나에 업데이트가 일어나면 다른 하나도 업데이트를 해줘야 하지만 Cache는 이 사실을 알 수 없음

- Virtually addressed, physically tagged caches
	![[Pasted image 20240608180203.png]]
	- Cache entry에 PPN에 대한 추가적인 정보가 존재함
----
### 19. Cache Coherence
----
- Shared memory multiprocessors (= symmetric multiprocessors, SMP)
- Distributed Memory Architecture ( = Non-Uniform Memory Access architecture, NUMA architecture)

- Cache Coherence
	- Directory based cache coherence protocol
		- cache line 각각에 대한 ownership을 cache에서  tracking하는 것
	- Snooping
		- broadcast를 통해  cache를 가지고 있는 core가 누구인지 알게 됨
	
	- Validate/Invalidate (MI protocol)
		- 다른 core가 가진 data를 읽고자 할 때 현재 owner를 invalidate하고 data를 넘겨 받음
	- MSI protocol
		- read면 data를 복사해서 가져옴
		- write를 통해 data를 업데이트하면 해당 data를 가지고 있는 다른 core들의 data도 업데이트를 함
	- MESI protocol
		- MSI에서 write의 경우 해당 data를 가지고 있는 다른 core들의 data를 다 가져옴(삭제함)
----
### 20. Storage Devices
----
- DRAM
	- Updatable
	- High density
- ROM
	- Nonvolatile
	- High density
- EPROM, EEPROM
	- Updatable
	- Nonvolatile
- FLASH
	- Updatable
	- High density
	- Nonvolatile

- FLASH
	- cell 기반
	
	- NOR flash memory
		- density가 낮아서 비싸고 느림
		- DRAM 대체 가능 (word 단위로 data 읽을 수 있음)
	
	- NAND flash memory
		- density가 높고 쌈
		- DRAM 대체 불가 (word 단위로 data 꺼내오지 못함)
		- data 저장용
		- types
			- 각 cell에 저장할 수 있는 bit 수에 따라
			- SLC
			- MLC
			- TLC
			- QLC
		- FTL (Flash Transition layer)
			- NAND flash memory의 내부 동작을 관리하는 소프트웨어 레이어
