# 제1장 데이터 명세 정보

- 데이터 요약: 자연어처리(NLP) 및 딥러닝 기술을 기반으로 낚시성 기사 등 낮은 품질의 기사로 인해 시간과 비용 낭비, 사실 왜곡 등 사회적 문제해결을 위한 인공지능 학습용 데이터

- 데이터 출처: 중앙일보 외 13개 언론사 기사 (정치, 경제, 사회, 생활&문화, IT&과학, 세계, 연예 7대 카테고리 기사)

- 다양한 매체유형별 데이터 수집
	- 매체 구분 별 수집데이터 현황
		- 전국종합일간(42.5%), 경제일간(29.0%), 통신사(7.0%), 지역종합일간 (6.2%), 종합·전문주간(6.2%), 전문일간(6.2%), 인터넷신문(2.8%)

- 카테고리별로 편향되지 않게 구성/학습요건 충족
	- 기사 카테고리별 원천/라벨링 데이터 현황
		- 정치(13.6%), 경제(14.2%), 사회(19.8%), 생활&문화(10.8%), IT&과학 (13.8%), 세계(15.5%), 연예(12.3%)

- 데이터 포맷
	![[Pasted image 20250907005929.png]]

- 직접생성 가공패턴유형별 데이터 분포
	![[Pasted image 20250907012031.png]]

- 낚시성 기사 자동생성 시 문장간 상호 대체를 고려하여 5문장 이하의 너무 짧은 기사는 배제 처리

- 문장이 너무 긴 경우 2가지 이상의 주제를 담고 있을 가능성이 높다는 점과 원천데이터 물량 확보 측면을 고려하여 50문장이 넘는 기사는 배제 처리

- 기사 데이터 수집 시 기사 본문에 이미지나 동영상만 있고, 텍스트 내용이 없는 경우 ‘제약있음’에 해당하여 제외 처리

- 기사 데이터 수집 시 본문의 텍스트 길이가 200자 미만인 기사의 경우 ‘제약있음’에 해당하여 제외 처리

- 기사 제목 어절 수 : 3어절 미만 기사 제거

- 기사 제목 글자 수 : 공백 포함 글자 수 기준 10자 미만 기사 제거

- 기사 본문 문장 수 : 5문장 이하인 기사, 50문장 이상 기사 제거

- 과제 요청사항에 해당하는 포탈 뉴스의 주요 카테고리인 정치, 경제, 사회, 생활&문화, IT&과학, 세계 6대 카테고리에 자문위원회의 의견에 따라 연예 카테고리를 추가하고, 스포츠 카테고리는 기사 특성 상 과제의 대상으로 부적합하다는 자문위원회의 의견에 따라 대상 카테고리에서 제외 처리

- 기존 기사에 대한 제목, 본문 문장은 그대로 유지하고, 새롭게 작성되는 새제목과 본문 문장은 별도로 구분하여 항목 및 항목 값으로 관리하고, AI 학습모델에 활용되도록 독립적으로 구성하여 구축

# 제2장 데이터 구축

- 학습모델 임무 : ‘낚시성 기사 탐지’에 대한 임무는 크게 분류(Classification), 그리고 주제 분리 탐지(Topic Segmentation Detction)로 정의

- 특정 기사 카테고리가 전체 데이터의 40%를 넘지 않도록 획득(수집)

- 총 30만 건 이상의 데이터 획득(수집)

- 원천데이터 규모
	![[Pasted image 20250907012937.png]]

- 원시데이터 정제 절차
	1. XML 파일 오류 Check
	2. XML 파일 DB 업로드
	3. XML 파일 내용 Check (크라우드워커를 통한 인적 정제)
	4. 프로그램 기반 정제
		1. 인적 정제 내용 반영
		2. 내용 전처리
		3. 정제 후 추가 처리
		4. 원천데이터 배분 및 생성
			- 세부구분(1세부/2세부), 용도구분(낚시성/非낚시성), 직접생성 가공패턴유형(1세부 6개, 2세부 4개)에 따라 사전에 계획된 배분율 및 2세부 가공 문장수 2~4랜덤 부여하여 기사들을 랜덤하게 추출 후 할당
	5. 원천데이터 백업 및 가공업체 전달

- 가공(라벨링)
	- 자동생성
		- 동일 카테고리 내에서 기사들 간의 제목(본문 문장) 대체
	- 직접생성
		- 크라우드워커를 통해 생성
		- 1세부
			- 각 기사에 할당되어 있는 패턴유형에 맞게 작성
		- 2세부
			- 기사마다 가공문장수를 2~4문장 랜덤하게 부여하고, 할당받은 기사에 대해서는 지정된 문장수 만큼을 작성
			- 첫문장의 서두에는 원문기사의 내용을 간략하게 요약한 내용을 포함하도록 작성

- 사용 제한 표현 : 욕설 및 혐오표현을 사용함으로써 기사에 사용하기 적절하지 않고 데이터의 목적에 부합하지 않은 표현은 사 용을 제한

- 학습모델 유효성 검사
	![[Pasted image 20250907024730.png]]

- 학습 모델 후보
	- 낚시성 기사 분류 1순위: HAND(Hierarchical Attention Network for Fake News Detection)
	- 주제분리 탐지 1순위: BERT(Bidirectional Encoder Representation from Transformers)


- 학습 모델 개발
	- 인공지능 기반 낚시성 뉴스 기사 분류 모델
		- 개발 목표: 본문과 다른 내용의 뉴스 기사 제목 데이터를 활용하여 낚시성 뉴스 기사 여부 판단
		- 개발 내용: 구축되는 학습데이터를 활용하여 제목과 본문 간 맥락 파악이 가능한 모델을 개발
	- 인공지능 기반 낚시성 기사 주제분리 탐지 모델
		- 개발 목표: 본문 내 일관성 없는 주제로 작성된 뉴스 기사 데이터를 활용하여 낚시성 뉴스 기사 여부 판단
		- 개발 내용: 일관성 여부에 따라 두 문장 간 맥락을 학습하여 본문 내 주제 분리 지점을 판단할 수 있는 모델을 개발

# 제3장 데이터 활용

- 데이터 명: 2-025-146. 낚시성 기사 탐지 데이터
- 학습 모델
	1. 낚시성 기사 분류 모델
	2. 뉴스 기사 주제분리 탐지 모델
- 모델
	1. 낚시성 기사 분류 모델 : HAND(Hirerarchical Attention Network for Fake News Detection)
	2. 뉴스 기사 주제분리 탐지 모델 : BERT(Bidirectional Encoder Representation from Transformers) 주제 분리 탐지
- 성능 지표
	1. 낚시성 기사 분류 모델 : Accuracy(정확도) - 목표 60% vs. 결과 87%
	2. 뉴스 기사 주제분리 주제분리 탐지 모델 : 정확도(Accuracy) 목표 55% vs. 결과 83.9% / F1-Score 목표 55% vs. 결과 90.8%
- 개발 내용
	1. 제목과 본문의 불일치 기사에 해당하는 1세부용 구축 학습데이터를 활용하여 새롭게 유입되는 뉴스기사에 대해 낚시성 기사 가능 점수 산출, 점수를 기반으로 분류 및 필터로 활용가능한 낚시성 기사 분류 모델(HAND) 개발
	2. 본문의 도메인 일관성 부족 기사에 해당하는 2세부용 구축 학습데이터를 활용하여 새롭게 유입되는 뉴스기사에 대해 본문 내에서 화제변환 여부, 화제 수 등의 정보를 산출하여 활용가능한 주제 분리 탐지 모델(BERT 주제 분리) 개발

- 본 과제에 사용된 제3자 제공 딥러닝 프레임워크 및 낚시성 기사 탐지 오픈 소스 모델

| 오픈소스명                                                              | 사용 목적                                    | 라이선스명                                         |
| ------------------------------------------------------------------ | ---------------------------------------- | --------------------------------------------- |
| [Pytorch](https://github.com/pytorch/pytorch)                      | 딥러닝 프레임워크                                | New and Simplified BSD License (BSD 3-Clause) |
| [BERT](https://github.com/huggingface/transformers)                | 낚시성 기사 탐지에 사용되는 언어모델 (ENG)               | Apache License 2.0                            |
| [KoBERT](https://github.com/SKTBrain/KoBERT)                       | 낚시성 기사 탐지에 사용되는 언어모델 (SKT에서 제공하는 한국어 버전) | Apache License 2.0                            |
| [Mecab-ko](https://bitbucket.org/eunjeon/mecab-ko-dic/src/master/) | 한국어 형태소 분석기                              | Apache License 2.0                            |
| [KoNLPy](https://github.com/konlpy/konlpy)                         | 한국어 형태소 분석기 및 품사 태깅                      | GNU General Public License 3.0                |

- 소스 코드 사용 매뉴얼
	1. 패키지 설치
		- 사용자의 실행 환경을 고려해 윈도우, 맥 OS, 리눅스 등 다양한 환경에서 소스코드를 설치하는 방법을 제공
	2. 공개된 낚시성 기사 탐지 데이터 불러오기
		- 본 과제를 통해 구축한 한국어 낚시성 기사 탐지 데이터셋을 불러오고 간단한 전처리를 수행함으로써 데이터셋을 낚시성 기사 탐지 모델에 입력할 수 있는 형태로 변환하는 예시를 제공
	3. 낚시성 기사 탐지 알고리즘 기능 설명
		- 패키지를 통해 제공되는 모든 낚시성 기사 탐지 알고리즘의 구체적인 사용 방법 제공
	4. 사용 예시
		- 데이터셋과 학습된 모델을 불러와서 낚시성 기사 탐지를 수행하거나 사용자가 직접 구축한 데이터를 이용해 탐지 모델을 학습하는 등 본 패키지로 할 수 있는 사용 예시들을 제공

