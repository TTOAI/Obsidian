## 전체 서비스 아키텍처

```bash
[사용자 FE(웹/모바일)]
        │  HTTPS
        ▼
[CloudFront + S3(정적 FE)]
        │  HTTPS
        ▼
[Spring Boot API (게이트웨이)]
  - Auth/비즈니스 로직/페이지네이션
  - RDS 단일 진실원장(SoT) 책임
  - OpenSearch 읽기(검색 결과 전달)
        │  내부 네트워크
        ▼
[AI 서비스(내부)]
  - 분류: ONNX (Lambda/FastAPI)
  - 요약: Bedrock 래퍼
  - 임베딩/색인 쓰기: OpenSearch
  - 캐시/버전 관리

────────────────────────── Data Stores (저장소 레이어) ──────────────────────────
[RDS (Aurora)]           [OpenSearch]                         [S3 Data Lake]
- SSOT(최종 저장)        - 텍스트/벡터 인덱스                 - raw / curated / embeddings / models
- Spring Boot 소유       - 읽기: alias "*_current" 고정       - Versioning ON
                         - 쓰기/스왑: AI 배치

────────────────────────── Batch / ML Orchestration ───────────────────────────
[EventBridge(스케줄)] ──▶ [Step Functions(오케스트레이터)]
   │
   ├─ (1) Fargate: 크롤링(Scrapy / scrapy-playwright)
   │        └─▶ S3 raw/{source}/YYYY/MM/DD/{url_hash}.html
   │
   ├─ (2) Lambda: 정제/중복검사(HTML → JSON)
   │        └─▶ S3 curated/YYYY/MM/DD/{url_hash}.json
   │        └─▶ Spring Boot 내부 API 호출 → RDS UPSERT(SSOT)
   │
   ├─ (3) (선택) SageMaker Processing: 임베딩 배치 생성
   │        └─▶ S3 embeddings/{model_version}/part-*.parquet
   │
   ├─ (4) Lambda: OpenSearch 벌크 색인(텍스트/벡터)
   │        └─▶ 새 인덱스(articles_text_vN / articles_vec_vN) 구축
   │
   ├─ (5) Lambda: OpenSearch alias 스왑(무중단 전환, *_current 교체)
   │
   └─ (6) 알림/지표 집계(Slack/Email, CloudWatch)

────────────────────────── External Managed Services ──────────────────────────
- AWS Bedrock(LLM 호출)  ← AI 서비스에서 사용
- ECR(컨테이너 레지스트리) ← Fargate가 크롤러 이미지 pull

```

## AI 서비스 호출 구조

```
[FE] → Spring Boot(API 게이트웨이 역할)
              └─ (사설망/VPC) → AI 서비스
```

- 장점: 인증/감사/요금제/에러 규격/캐시를 **한 곳(Spring Boot)**에서 통일
- 보안: AI 서비스는 외부 비공개(사설망)
- 운영 단순: FE는 한 API만 상대, 백엔드는 내부에서 AI 호출·병합

## 크롤링/배치

- **크롤링을 위해 필요한 서비스 및 용어 정리**
    1. Fargate
        - AWS에서 제공하는 서버리스 컨테이너 실행 서비스
        - “이 컨테이너를 이렇게 돌려줘”라고만 하면 AWS가 알아서 서버 자원을 할당
        - 활용: 크롤러 코드를 Docker 컨테이너로 만들고 Fargate에서 실행시킴
    2. EventBridge
        - AWS의 이벤트 버스 서비스
        - 활용: EventBridge에서 스케줄러 설정 → 특정 조건 하에서 Fargate에 있는 크롤링 컨테이너 실행
    3. Scrapy
        - 파이썬 기반 웹 크롤링 프레임워크
        - 빠른 HTML 파싱, 크롤링 스케줄 관리, 결과 저장에 특화
        - 정적 HTML 구조로 제공되는 페이지에는 Scrapy만으로 충분
        - 활용: 뉴스 기사를 크롤링하여 DB나 S3에 저장
    4. 동적 렌더링 (Dynamic Rendering)
        - 웹페이지가 처음에는 빈 HTML만 주고, 자바스크립트 실행 후 실제 내용을 채워 넣는 방식
        - 현대 웹사이트 대부분이 이 방식(React, Vue, Angular 기반)
        - 단순 HTML 파싱으로는 데이터가 안 보임
    5. scrapy-playwright
        - Playwright는 실제 브라우저(Chromium, Firefox 등)를 자동으로 띄워서 JS 실행 → 최종 렌더링된 HTML을 가져올 수 있음
        - scrapy-playwright는 Scrapy 안에서 이 Playwright 기능을 활용할 수 있게 해주는 라이브러리
        - 동적 렌더링이 필요한 페이지를 크롤링할 수 있게 해줌
        - 활용: “기사 더보기 버튼”을 눌러야 본문이 다 보이는 페이지 크롤링
    6. ECR (Elastic Container Registry)
        - AWS에서 제공하는 Docker 이미지 저장소
        - 보안, 속도, 권한 관리, 비용/정책 측면에서 DockerHub보다 ECR이 안전하고 빠름
    7. Docker 컨테이너
        - 로컬 개발환경에서 먼저 Dockerfile로 이미지 생성
        - ECR(AWS Elastic Container Registry)에 푸시해 저장
        - 활용: “크롤링 서비스 컨테이너”, “AI 추론 서비스 컨테이너” 따로 만들어 ECR에 올리고, 필요할 때 Fargate나 ECS에서 실행
    8. S3
        - S3 raw: 크롤링한 원문 그대로 저장하는 영역
        - S3 curated: 원문에서 필요한 정보만 뽑아 정리된 JSON
        - 원본(raw) → 정제(curated) → 서비스/RDS 반영의 흐름
        - Versioning: 같은 이름의 파일을 덮어쓸 때, 이전 버전도 자동으로 보관되는 S3 기능
    9. ETL
        - Extract: 크롤링 (raw 저장)
        - Transform: 정제(curated) → 모델 Input 스키마로 맞춤
        - Load: AI 모델 서비스에 전달 → 추론 결과 받기
    10. Step Functions
        - 여러 AWS 서비스를 워크플로우로 연결하는 서비스
    11. SSOT
        - 단일 진실 공급원
        - 모든 데이터가 한 곳에서 관리되어 데이터의 일관성과 정확성을 높임
        - 예: RDS
    12. SageMaker
        - AWS에서 제공하는 완전 관리형 기계 학습 서비스
        - 데이터 처리(Processing / Pipeline): 전처리·후처리 작업 자동화
        - 대규모 데이터 학습, 분산 학습, 자동 하이퍼파라미터 튜닝(Autopilot), 실시간 배포(Endpoint)까지 원스톱으로 가능
        - 운영 환경(모니터링, 배포 자동화, 보안 IAM 연동)에 최적화
        - AutoML, Debugging, Monitoring 같은 부가 기능 제공
        - 기업/연구소 수준에서 수십~수백 GB 이상의 데이터를 다루거나, GPU/TPU 클러스터가 필요한 경우
        - 소규모 프로젝트에서는 Colab/로컬에서 fine-tuning → ONNX 변환 후 Lambda/Fargate에서 서빙하는 것이 더 나음
    13. ONNX
        - 다양한 딥러닝 프레임워크(PyTorch, TensorFlow, MXNet…)에서 만든 모델을 표준화된 형식으로 저장할 수 있게 해주는 공통 포맷
        - ONNX Runtime을 통해 다양한 언어·환경에서 빠르게 실행 가능
        - 예시
            - 모델 학습 단계: Colab/PyTorch에서 모델 학습
            - 배포 단계: 모델을 ONNX로 변환 후 → AWS Lambda 또는 Fargate에 올림
            - 실행 엔진: Lambda/Fargate 안에서 onnxruntime 라이브러리로 추론
- **크롤링 워크플로우**
    1. EventBridge
        - 정해진 시간마다 자동으로 실행 트리거를 발생
    2. Step Functions (오케스트레이션)
        - 전체 워크플로우를 순서대로 관리
        - 없이 EventBridge → Lambda 만으로 시작 가능
    3. Fargate (크롤링 실행)
        - Scrapy/Playwright가 들어있는 Docker 컨테이너 실행
        - 뉴스 웹페이지 크롤링 후 원문 HTML/스크린샷을 S3 raw에 저장
    4. S3 raw
        - 원문 데이터(HTML/스크린샷)를 그대로 저장하는 버킷
        - 언제든지 다시 정제하거나 재처리할 수 있게 원본을 보관
    5. Lambda (데이터 정제)
        - 크롤링된 데이터를 JSON 구조로 깔끔하게 변환
        - 결과는 S3 curated에 저장
    6. S3 curated
        - AI와 DB가 쓰기 좋은 구조화된 데이터 저장소
        - "가공된 버전의 뉴스 데이터"가 모이는 곳
    7. Lambda (AI 호출)
        - 모델을 호출해서 기사에 대한 예측이나 요약을 수행
        - 결과를 다시 넘김
    8. Lambda (DB 저장)
        - AI 결과와 메타데이터를 **RDS(MySQL/Postgres)**에 저장
        - RDS는 SSOT 역할을 함
    9. 알림 (Slack/Email)
        - 파이프라인 완료 시 개발팀/운영팀에 알림 전송

## S3 - AI 부분

- **관련 용어 정리**
    1. 임베딩(embedding)
        - 글자·단어·문서 같은 비정형 데이터(텍스트)를, 컴퓨터가 다루기 좋은 숫자 벡터로 바꾸는 것
        - 두 벡터 사이의 거리(코사인 유사도)를 계산해서, 문서 간 의미적 유사도를 비교할 수 있음
        - 검색/추천/클러스터링에 필요
        - OpenSearch 같은 벡터DB에 색인하려면 필수
- **S3 버킷**
    1. imfact-raw/
        
        - 디렉터리 구조 예시
        
        ```bash
        imfact-raw/
        ├── raw/                                  # 원문(불변, 덮어쓰기 금지)
        │   └── {source}/YYYY/MM/DD/
        │       ├── {url_hash}.html               # 수집 원문
        │       ├── {url_hash}.png                # 선택: 스크린샷
        │       └── meta/
        │           └── {url_hash}.json           # 크롤링 메타(HTTP, 수집시각 등)
        │
        ├── curated/                              # 1차 정제본(JSON 스키마 고정)
        │   └── YYYY/MM/DD/
        │       └── {url_hash}.json               # title, content, author, published_at, …
        │
        ├── features/                             # 모델 입력에 쓰이는 파생물
        │   ├── embeddings/
        │   │   └── {model_version}/
        │   │       └── part-*.parquet            # 배치 임베딩 결과(벡터 테이블)
        │   └── nlp/                              # 토큰 통계/언어학적 피처(선택)
        │       └── YYYY/MM/DD/*.parquet
        │
        └── _logs/                                # ETL/배치 로그(선택)
            └── step-functions/…
        ```
        
        - 데이터 레이크
        - 권장 설정: Versioning=ON, Lifecycle(예: raw/는 90일 후 Glacier Deep Archive), SSE-KMS
        - 참조 키: 모든 계층이 {url_hash} 기준으로 trace 가능
        - 불변성 원칙: raw/는 append-only, curated/·features/는 재생성 시 새 파일(덮어쓰기 최소화)
        - raw/
            - 크롤링 직후 원천 데이터와 1차 가공본을 모아둠
        - curated/
            - raw를 전처리해 정형화된 JSON 구조로 만든 데이터
        - features/
            - raw/curated 데이터를 더 가공해서 나온 중간 산출물
            - 배치 임베딩 결과 → embeddings/
            - 토큰 통계 → nlp/
    2. imfact-models/
        
        - 디렉터리 구조 예시
        
        ```bash
        imfact-models/
        └── clickbait/
            ├── 2025-08-17-v5/                # 불변 버전 폴더
            │   ├── model.onnx
            │   ├── tokenizer/                # 토크나이저 리소스
            │   │   ├── tokenizer.json | vocab.txt | merges.txt
            │   ├── calibration.json          # 확률 보정 파라미터(Temperature/Platt)
            │   ├── label_map.json            # 라벨 인덱스 ↔ 이름
            │   ├── meta.json                 # 성능/데이터/코드 커밋 등 메타
            │   └── checksums.txt             # 무결성(SHA256/MD5 등)
            │
            ├── cbt_candidate/                # 카나리/샤도우 검증용 “가변 슬롯”
            │   └── ... (동일한 파일 셋)
            │
            └── cbt_current/                  # 운영이 읽는 “고정 경로”
                └── pointer.json              # {"target":"2025-08-17-v5"}
        ```
        
        - 모델/서빙 아티팩트 저장소
        - 운영 서비스는 항상 cbt_current/만 봄
        - 승격/롤백은 pointer.json만 바꾸면 끝(무중단)
    3. imfact-config/
        
        ```bash
        imfact-config/
        ├── rules/
        │   ├── lexicon/
        │   │   ├── ko_clickbait_v1.json          # 자극어 사전/가중치
        │   │   └── ko_clickbait_v2.json
        │   └── rules_v1.yaml                     # 규칙 기반 penalty/bonus 정의
        │
        ├── thresholds/
        │   └── clickbait.json                    # {"T":0.55, "unsure_band":[0.48,0.62]}
        │
        ├── routing/
        │   └── model_alias.json                  # {"cbt_current":"2025-08-17-v5"}
        │
        ├── pipeline/
        │   ├── opensearch_alias.json             # {"text":"articles_text_current", …}
        │   └── batch_params.yaml                 # 벌크 크기, 재시도, 타임아웃 등
        │
        └── secrets_placeholders/                 # 실제 비밀은 Secrets Manager 사용
            └── README.md
        ```
        
        - 원칙: 모델 파일을 바꾸지 않고도 운영 정책을 신속히 바꾸기 위한 분리
        - 권한: 운영/리드만 쓰기(Write), 애플리케이션은 읽기(Read-only)

## AI 모델 학습/서빙

- 관련 서비스
    1. Elastic Beanstalk
    2. ECS
    3. FastAPI
    4. Bedrock
    5. ONNX
- 처음에는 Elastic Beanstalk → ECS
- 처음에는 Bedrock → ECS(FastAPI) + ONNXruntime
- **워크플로우**
    1. 데이터 & 체크포인트 저장소 → S3
    2. ## Colab 학습
        

## 검색/벡터

- 관련 서비스
    1. OpenSearch