
## robots.txt

- 웹사이트에서 자동화된 데이터 수집을 어디까지 허용하고, 어디까지 허용하지 않을지를 지정한 문서
- 보통 웹사이트의 루트 디렉토리에 위치시킴 (ex. https://www.google.com/robots.txt)
```
User-agent: -> 모든 데이터 수집 자동화 프로그램에 대해
Disallow: /search -> google.com/search 아래의 경로는 데이터 수집을 허용하지 않음
Allow: /search/about -> google.com/search/about 아래의 경로는 데이터 수집을 허용함
  ```
  - robots.txt를 통해 웹사이트 내에 자동화된 데이터 수집이 가능한 영역을 확인하고 그 지침을 준수해 웹 스크래핑을 진행해야 함

## 웹 크롤링

- 주로 검색 엔진에서 사용하는 기술
- 웹사이트를 순회하면서 대규모의 데이터를 수집
- 웹 크롤링 프로그램은 웹 크롤러, 스파이더, 로봇 등으로 불림
	1. 웹사이트의 전체 구조를 맵핑
	2. 모든 링크를 따라서 페이지 간의 관계를 파악하면서 웹 페이지의 내용을 수집
	3. 검색 엔진의 데이터베이스에 저장
	4. 저장된 데이터를 이용해 검색엔진이 검색 결과를 제공

## 웹 스크래핑

- 특정 웹 페이지에서 필요한 데이터를 추출하는 과정
- 주로 특정 데이터 수집을 목적으로 함 (주식 가격, 제품 리뷰, 뉴스 기사 등)

- 도구 종류:
	-  BeautifulSoup
		- HTML, XML 파일을 파싱하기 위한 파이썬 라이브러리
		- 주로 정적 웹 페이지에서 효과적으로 데이터 추출
	- Selenium
		- 웹 브라우저를 자동으로 조작할 수 있는 도구
		- 동적 웹 페이지에서 스크립트가 생성하는 모든 동적 내용 포착 가능

## User Agent

- 웹 서버로 요청을 보낼 때 요청을 보낸 브라우저의 고유한 식별 정보를 담고 있는 헤더
- 사용자 운영 시스템과 브라우저에 최적화된 컨텐츠를 제공하거나 브라우저가 지원하지 않는 기능을 웹 페이지에서 사용하지 않도록 조정 가능

- user agent 확인하는 사이트:
	- https://www.whatismybrowser.com/detect/what-is-my-user-agent/

- chrome으로 접속했을 때 나의 user agent:
	- `Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36`

- 웹 서버에 요청을 보낼 때 header에 자신의 User Agent 값을 넣음으로써 마치 사람이 직접 브라우저로 접속하는 것처럼 요청할 수 있음

## BeautifulSoup

- BeautifulSoup 객체
	- HTML 파일을 파싱하고 파싱된 데이터를 탐색하고 수정하는 데 사용
	- 파싱을 진행할 HTML 문서를 객체에 전달하는 두 가지 방식:
		- 확장자가 .html로 저장된 파일을 with open() 으로 파이썬에서 연 다음 BeautifulSoup()에 전달
		- Requests로 받은 HTML 문서를 문자열로 전달
	- 매개변수 parser로 파서의 종류 지정

- find 메서드
	- 태그를 이용하여 조건에 부합하는 태그를 찾아서 결과를 추출
	- 종류: find(), find_all()
	- find()
		- 조건을 만족하는 첫 번째 태그 추출

- select 메서드
	- find와 마찬가지로 태그를 이용하여 조건에 맞는 태그를 찾아서 결과 추출
	- CSS 선택자를 사용해 태그를 찾음
	- 종류: select(), select_one()

- 그외 탐색 방법
	- soup.태그명

- Beautiful Soup 공식 문서: https://www.crummy.com/software/BeautifulSoup/bs4/doc/

## newspaperk3 사용하기

- `!pip install newspaper3k`
	- `newspaper3k` 라이브러리는 내부적으로 **`lxml.html.clean`** 모듈을 사용함
	- `lxml` 최신 버전에서는 이 모듈이 빠져서 별도 패키지(`lxml_html_clean`)로 분리
	- 따라서 최신 버전을 반영하기 위해 `lxml_html_clean`을 따로 설치해야 함
	- `!pip install lxml_html_clean` 추가

- `Article()` 객체를 이용해 기사 `url`만으로 기사의 제목, 저자, 본문 등과 같은 정보를 추출할 수 있음

## 다음 뉴스 웹사이트의 `url` 구조

- https://news.daum.net/
	- https://news.daum.net/home
		- https://news.daum.net/magazine
	- https://news.daum.net/climate
		- 기후・환경 주요뉴스
		- 기후위기 - https://news.daum.net/climatecrisis
			- 프리미엄 시리즈
				- `title_view` class 태그 또는 `summary_view` class 태그:
					- `[시리즈 제목] ...` 또는 `... [시리즈 제목]`
			- 심층탐사보도
				- `title_view` class 태그 또는 `summary_view` class 태그:
					- `[시리즈 제목] ...` 또는 `... [시리즈 제목]`
			- 기후위기 주요뉴스
			- 이 시각 주요뉴스
			- '발로 뛰다' 현장/르포 - https://issue.daum.net/news/reportage
		- 환경 - https://news.daum.net/environment
		- 기후/환경 최신 뉴스
		- 이 시각 주요뉴스
		- '발로 뛰다' 현장/르포 - https://issue.daum.net/news/reportage
	- https://news.daum.net/world
		- 국제 주요뉴스
		- 국제 정세 - https://news.daum.net/global
			- 심층탐사보도
			- 프리미엄 시리즈
			- 국제정세 주요뉴스
			- 이 시각 주요뉴스
			- '발로 뛰다' 현장/르포 - https://issue.daum.net/news/reportage
		- ...
		- 포토 뉴스 - 제목: [포토] ...
		- 국제 최신 뉴스
		- 이 시각 주요뉴스
		- '발로 뛰다' 현장/르포 - https://issue.daum.net/news/reportage
		- 북미 - https://news.daum.net/northamerica
		- ...
	- ...
- https://entertain.daum.net/
- https://sports.daum.net/
- https://weather.daum.net/
- 뉴스 기사 페이지
	- https://v.daum.net/v/{yyyy}{MM}{dd}{HH}{mm}{00000}

## 다음 뉴스 웹사이트의 페이지 구조 및 HTML 구조 분석

- 일반적인 특징
	- 카테고리 페이지 상에 있는 박스(nullable):
		- class="content-article"
			- `... 주요뉴스`
				- class="box_comp box_news_headline2"
			- `세부 카테고리` 박스들
				- class="box_comp box_news_block"
				- 상단바의 카테고리명과 차이날 수 있음
				- 상단바에는 있는데 박스가 없을 수도 있음
			- `포토 뉴스`
		- class="content-aside"
			- `... 최신 뉴스`
				- class="box_comp box_news_basic"
			- `이 시각 주요뉴스`
				- class="box_comp box_news_basic"
			- `'발로 뛰다' 현장/르포`
				- class="box_comp box_news_block"
	- 세부 카테고리 페이지 상에 있는 박스(nullable):
		- class="content-article"
			- `프리미엄 시리즈`
				- class="box_comp box_news_block"
			- `심층탐사보도`
				- class="box_comp box_news_basic"
			- `... 심층탐사(보도)`
				- class="box_comp box_news_basic"
			- `... 주요뉴스`
				- class="box_comp box_news_headline2"
			- `최신 뉴스`
				- class="box_comp box_news_basic"
			- `실시간 기사 보기`
		- class="content-aside"
			- `이 시각 주요뉴스`
				- class="box_comp box_news_basic"
			- `'발로 뛰다' 현장/르포`
				- class="box_comp box_news_block"
	- `프리미엄 시리즈`
		- `title_view` class 태그 또는 `summary_view` class 태그:
			- `[시리즈 제목] ...` 또는 `... [시리즈 제목]`
	- `심층탐사보도`
		- `title_view` class 태그 또는 `summary_view` class 태그:
			- `[시리즈 제목] ...` 또는 `... [시리즈 제목]`
	- 일반적인 특징을 안 따르는 카테고리:
		- `인물`, `지식/칼럼`, `연재`
		- class="box_comp box_news_thumb"

- 일반적인 특이점
	- 상단바에 적힌 카테고리명과 페이지 상에 적힌 카테고리명이 약간 차이날 수 있음
	- 일부 세부 카테고리에 있는 박스:
		- `최신 뉴스`
		- `실시간 기사 보기`
		- 여러 종류의 `... 심층탐사보도`
	- 카테고리 페이지 상에 세부 카테고리가 없으면, 세부 카테고리 페이지 상에 `주요 뉴스` 박스가 없음

- 세부 특이점
	- `사회`, `국제`는 페이지 맨 아래에 `포토 뉴스`가 있음
	- `사회` 페이지 상에 `시사`가 없음
		- `시사` 페이지 상에 `주요 뉴스` 박스가 없음
		- `시사` 페이지 상에 있는 박스:
			- `'시사' 심층탐사보도`
			- `'현대사' 심층탐사보도`
			- `'추적보도' 심층탐사`
			- `프리미엄 시리즈`
	- `국제` 페이지 상에 `해외화제`가 없음
		- `해외화제` 페이지 상에 `주요 뉴스` 박스가 없음
		- `해외화제` 페이지 상에 `해외화제 최신 뉴스` 박스만 있음 
	- `사회`의 `인권/복지` -> `심층탐사보도` 외에 `'장애인' 심층탐사보도` 있음
	- `문화`에 `심층탐사보도`가 없음
	- `생활`에 `심층탐사보도`가 있는 것도 있고 없는 것도 있음
	- `생활`에 여러 종류의 `심층탐사보도`가 있는 세부 카테고리가 있음
	- `인물`에 `인물 주요뉴스`가 없음
	- `지식/칼럼` 페이지 상에 `지식/칼럼 주요뉴스`,  `사설`, `포토` 박스가 없음
		- `지식교양` 박스에 `에세이` 세부 카테고리가 있음
	- `지식/칼럼`의 `지식교양` 페이지 상에 있는 박스:
		- `지식과 교양`
		- `역사의 현장`
		- `식물 탐구`
		- `건축과 공간`
	- `지식/칼럼`의 `에세이` 페이지 상에 `에세이` 박스만 있음
	- `지식/칼럼`의 `의견칼럼` 페이지 상에 있는 박스:
		- `시사종합`
		- `경제지`
		- `전문지`
		- `지역지`
	- `지식/칼럼`의 `사설` 페이지 상에 있는 박스:
		- `시사종합`
		- `경제지`
		- `전문지·통신사`
		- `지역지`
	- `지식/칼럼`의 `만평` 페이지 상에 있는 박스:
		- 여러 언론사들의 만평
	- `지식/칼럼`의 `팩트체크` 페이지 상에 있는 박스:
		- `언론사별 팩트체크`
	- `지식/칼럼`의 `포토` 페이지 상에 있는 박스:
		- `포토 에세이`
		- `사진으로 본 오늘`
		- `사진으로 보는 ...` -> 중동/아랍, 아시아, 아메리카, 유럽, 아프리카, 오세아니아
	- `연재` 페이지 상에 있는 박스:
		- 다양한 연재 시리즈

## HTML 구조 파악하는 방법

- 크롤링하고자 하는 뉴스 페이지 url 복사
- 개발자도구에서 `ctrl + F`
- url 붙여넣기
- 위치 및 HTML 구조 파악

